#include "stdheader.glsl"

layout(binding = 4, std140) uniform LightPathTrace
{
	int NumRaysPerLightSample;
	float LightRayPixelWeight; // (Total num pixels) / (Total num light rays) 
};


// The problem: There is no atomic vec4 operation, even with GL_NV_shader_atomic_float
// The solution: (Spin)Locks for every output pixel. (http://stackoverflow.com/questions/10652862/glsl-semaphores)
// A possible alternative solution: Gather all events in an "append buffer" and apply them via classic vertex scattering (point rendering) and blending

// coherent is necessary!
layout(binding = 0, rgba32f) coherent uniform image2D OutputTexture;
layout(binding = 1, r32ui) coherent uniform uimage2D LockTexture;

layout (local_size_x = 64, local_size_y = 1, local_size_z = 1) in;
void main()
{
	uint randomSeed = InitRandomSeed(FrameSeed, gl_GlobalInvocationID.x);
	int lightSampleIndex = int(gl_GlobalInvocationID.x / NumRaysPerLightSample);

	// TODO: Force whole group to operate on the same initial sample and load the sample into sharedmem
	Ray ray;
	vec4 lightSamplePos_Norm0 = texelFetch(InitialLightSampleBuffer, lightSampleIndex * 2);
	vec4 lightFlux_Norm1 = texelFetch(InitialLightSampleBuffer, lightSampleIndex * 2 + 1);
	vec3 rayFlux = lightFlux_Norm1.xyz * LightRayPixelWeight;
	ray.Origin = lightSamplePos_Norm0.xyz;

	vec3 normal = UnpackNormal(vec2(lightSamplePos_Norm0.w, lightFlux_Norm1.w));
	vec3 U, V;
	CreateONB(normal, U, V);
	ray.Direction = SampleUnitHemisphere(Random2(randomSeed), U, V, normal);

	for(int i=0; i<MAX_PATHLENGTH; ++i)
	{
		// Trace ray.
		Triangle triangle;
		vec3 barycentricCoord;
		float rayHit = RAY_MAX;
		TraceRay(ray, rayHit, barycentricCoord, triangle);
		if(rayHit == RAY_MAX)
			break;

		// Compute hit normal and texture coordinate.
		vec3 hitNormal; vec2 hitTexcoord;
		GetTriangleHitInfo(triangle, barycentricCoord, hitNormal, hitTexcoord);
		// Get Material infos.
		MaterialTextureData materialTexData = SampleMaterialData(triangle.w, hitTexcoord);

		// Try to connect to camera.
		ray.Origin = ray.Origin + rayHit * ray.Direction;	// Go to surface with recursive ray (no epsilon yet!)
		Ray cameraRay;
		cameraRay.Direction = CameraPosition - ray.Origin;
		float camViewDotRay = -dot(CameraW, cameraRay.Direction);
		if(camViewDotRay > 0.0) // Camera faces point?
		{
			// Compute screen coord for this ray.
			vec3 proj = vec3(-dot(CameraU, cameraRay.Direction), -dot(CameraV, cameraRay.Direction), camViewDotRay);
			vec2 screenCoord = proj.xy / proj.z;
			screenCoord.x /= dot(CameraU,CameraU);
			screenCoord.y /= dot(CameraV,CameraV);

			// Valid screencoors
			if(screenCoord.x >= -1.0 && screenCoord.x < 1.0 && screenCoord.y > -1.0 && screenCoord.y <= 1.0)
			{
				float cameraDistSq = dot(cameraRay.Direction, cameraRay.Direction);
				float cameraDist = sqrt(cameraDistSq);
				cameraRay.Direction /= cameraDist;
				cameraRay.Origin = cameraRay.Direction * RAY_HIT_EPSILON + ray.Origin;

				// Hits *pinhole* camera
				if(!TraceRayAnyHit(cameraRay, cameraDist))
				{
					// Compute pdf conversion factor from image plane area to surface area.
					// The problem: A pixel sees more than only a point! -> photometric distance law (E = I cosTheta / dÂ²) not applicable!
					// -> We need the solid angle and the projected area of the pixel in this point!
					// Formulas explained in (6.2) http://www.maw.dk/3d_graphics_projects/downloads/Bidirectional%20Path%20Tracing%202009.pdf
					// Also a look into SmallVCM the is a good idea!
					
					// The distance to the image plane  is length(CameraW) == 1.
					// 1/cos == length(pixelPos)
					// vec3 pixelPos = CameraU * screenCoord.x + CameraV * screenCoord.y + CameraW;
					
					float cosAtCameraPow4 = camViewDotRay / cameraDist; // = dot(-cameraRay.Direction, CameraW);
					cosAtCameraPow4 *= cosAtCameraPow4;
					cosAtCameraPow4 *= cosAtCameraPow4;
					float fluxToRadiance = 1.0 / (cosAtCameraPow4 * PixelArea * cameraDistSq);
					float fluxToIrradiance = fluxToRadiance * dot(cameraRay.Direction, hitNormal);

					vec3 brdf = BRDF(cameraRay.Direction, ray.Direction, triangle.w, materialTexData, hitNormal);
					vec3 color = rayFlux * fluxToIrradiance * brdf;

					// Add Sample.
					ivec2 pixelCoord = ivec2((screenCoord*0.5 + vec2(0.5)) * BackbufferSize);

					// Lock pixel - there is a lot you can do wrong!
					// * ..due to shared command counter
					// * ..due to buggy glsl optimizations
					// -> Good overview: http://stackoverflow.com/questions/21538555/broken-glsl-spinlock-glsl-locks-compendium
					bool hasWritten = false; // Do not use break; instead. There's a bug in the GLSL optimizer!
					do {
						if(imageAtomicCompSwap(LockTexture, pixelCoord, uint(0), uint(1)) == 0)
						{
							memoryBarrier();

							// Add sample
							vec4 imageVal = imageLoad(OutputTexture, pixelCoord);
							imageStore(OutputTexture, pixelCoord, vec4(imageVal.xyz + color, imageVal.w));
							
							// Release Lock
							imageAtomicExchange(LockTexture, pixelCoord, 0);
							hasWritten = true;
						}
					} while(!hasWritten);
				}
			}
		}

		//if(i+1 < MAX_PATHLENGTH) // Not using is faster on GK104 on 18.11.14
		if(!ContinuePath(rayFlux, ray, randomSeed, hitNormal, triangle.w, materialTexData))
			break;
	}
}