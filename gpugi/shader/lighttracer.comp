#version 440

#ifdef SAVE_LIGHT_CACHE
	#define SAMPLEBSDF_OUTPUT_PDF
#endif

#define TRINORMAL_OUTPUT
#include "stdheader.glsl"

#ifdef SAVE_LIGHT_CACHE
	#include "lightcache.glsl"
#else
    layout(binding = 4, std140) uniform LightPathTrace
    {
        int NumRaysPerLightSample;
    };
#endif

#include "screenreproject.glsl"


#ifdef SAVE_LIGHT_CACHE
	#define MAX_PATHLENGTH 6
#else
	#define MAX_PATHLENGTH 16
#endif


layout (local_size_x = 64, local_size_y = 1, local_size_z = 1) in;
void main()
{
#ifdef SAVE_LIGHT_CACHE
	// Not entirely sure if this is 100% reliable!
	// Idea is to keep the counter on GPU without any CPU interaction.
	// Problems could arise if a thread uses "NumLightCacheEntries" before Thread0 wrote this number.
	// This may happen if the GPU does not schedule block 0 as first.
	if(gl_GlobalInvocationID.x == 0)
	{
		NumLightCacheEntries = NumRaysPerLightSample * NumInitialLightSamples;
		#ifdef SAVE_LIGHT_CACHE_WARMUP
			LightPathLengthSum = 0;
		#endif
	}
	memoryBarrierBuffer();
#endif

	uint randomSeed = InitRandomSeed(FrameSeed, gl_GlobalInvocationID.x);
	int lightSampleIndex = int(gl_GlobalInvocationID.x / NumRaysPerLightSample);
	vec4 lightSamplePos_Norm0 = texelFetch(InitialLightSampleBuffer, lightSampleIndex * 2);
	vec4 lightIntensity_Norm1 = texelFetch(InitialLightSampleBuffer, lightSampleIndex * 2 + 1);

#if defined(SAVE_LIGHT_CACHE) && !defined(SAVE_LIGHT_CACHE_WARMUP)
	// recursive MIS construction.
	float pathProbability = 1.0;
	float anyPathProbabilitySum = 0.0;

	// Correct init of "NumLightCacheEntries" required!
	// Each thread writes its own initial light sample into the LightCache
	LightCacheEntries[gl_GlobalInvocationID.x].Flux = lightIntensity_Norm1.xyz / PI_2 / NumRaysPerLightSample; // equal distributed in all directions, NumRaysPerLightSample times
	LightCacheEntries[gl_GlobalInvocationID.x].MaterialIndex = -1;
	LightCacheEntries[gl_GlobalInvocationID.x].Position = lightSamplePos_Norm0.xyz;
	LightCacheEntries[gl_GlobalInvocationID.x].Normal0 = lightSamplePos_Norm0.w;
	LightCacheEntries[gl_GlobalInvocationID.x].Normal1 = lightIntensity_Norm1.w;
	LightCacheEntries[gl_GlobalInvocationID.x].PathProbability = pathProbability;
	LightCacheEntries[gl_GlobalInvocationID.x].AnyPathProbabilitySum = anyPathProbabilitySum;
	//LightCacheEntries[gl_GlobalInvocationID.x].Texcoord // texcoord empty
	//LightCacheEntries[gl_GlobalInvocationID.x].IncidentDirection // direction empty
	#ifdef SHOW_SPECIFIC_PATHLENGTH
	LightCacheEntries[gl_GlobalInvocationID.x].PathLength = 0; // For debugging only
	#endif
#endif


	// Keep in mind that we are tracing flux = photons!
	// TotalFlux = Integral(I0 * cos Angle) dangle = I0 * PI
	vec3 pathThroughput = lightIntensity_Norm1.xyz * (PI / NumRaysPerLightSample);
	
	Ray ray;
	ray.Origin = lightSamplePos_Norm0.xyz;
	// Omnidirectional light?
	if(lightIntensity_Norm1.w > 1.0)
	{
		ray.Direction = SampleDirection(Random2(randomSeed));
		pathThroughput *= 4.0; // The above integration is for Lambertian emitters, need to correct this
	} else {
		vec3 normal = UnpackNormal(vec2(lightSamplePos_Norm0.w, lightIntensity_Norm1.w));
		vec3 U, V;
		CreateONB(normal, U, V);
		ray.Direction = SampleHemisphereCosine(Random2(randomSeed), U, V, normal);
	}

	for(int i=0; i<MAX_PATHLENGTH; ++i)
	{
		// Trace ray.
		Triangle triangle;
		vec3 barycentricCoord;
		float rayHit = RAY_MAX;
		vec3 geometryNormal;
		TraceRay(ray, rayHit, barycentricCoord, triangle, geometryNormal);
		if(rayHit == RAY_MAX)
			break;
		//geometryNormal = normalize(geometryNormal); geometryNormal is not normalize, but it actually does not need to be! See AdjointBSDFShadingNormalX functions
		ray.Origin = ray.Origin + rayHit * ray.Direction;	// Go to surface with recursive ray (no epsilon yet!)

		// Compute hit normal and texture coordinate.
		vec3 shadingNormal; vec2 hitTexcoord;
		GetTriangleHitInfo(triangle, barycentricCoord, shadingNormal, hitTexcoord);

		// Get Material infos.
		MaterialData materialData = SampleMaterialData(triangle.w, hitTexcoord);

		// Save light cache entry.
#ifdef SAVE_LIGHT_CACHE 
		uint lightCacheEntryIndex = atomicAdd(NumLightCacheEntries, 1);
	#ifdef SAVE_LIGHT_CACHE_WARMUP
		atomicAdd(LightPathLengthSum, 1);
	#else
		if(lightCacheEntryIndex < LightCacheCapacity)
		{
			LightCacheEntries[lightCacheEntryIndex].Flux = pathThroughput;
			LightCacheEntries[lightCacheEntryIndex].MaterialIndex = triangle.w;
			// Use "true" position - necessary epsilon can be easily applied in pathtracer_bidir.comp
			LightCacheEntries[lightCacheEntryIndex].Position = ray.Origin; 
			vec2 packedNormal = PackNormal(shadingNormal);
			LightCacheEntries[lightCacheEntryIndex].Normal0 = packedNormal.x;
			LightCacheEntries[lightCacheEntryIndex].Normal1 = packedNormal.y;
			LightCacheEntries[lightCacheEntryIndex].Texcoord = hitTexcoord;
			LightCacheEntries[lightCacheEntryIndex].IncidentDirection = ray.Direction;
			LightCacheEntries[lightCacheEntryIndex].PathProbability = pathProbability;
			LightCacheEntries[lightCacheEntryIndex].AnyPathProbabilitySum = anyPathProbabilitySum;
		#ifdef SHOW_SPECIFIC_PATHLENGTH
			LightCacheEntries[lightCacheEntryIndex].PathLength = i+1; // For debugging only
		#endif
		}
	#endif
#endif

		// Path length debugging.
	#ifdef SHOW_SPECIFIC_PATHLENGTH
		if(i+1 == SHOW_SPECIFIC_PATHLENGTH)
		{
	#endif

		// Try to connect to camera.
	#ifndef SAVE_LIGHT_CACHE_WARMUP
		Ray cameraRay;
		cameraRay.Direction = CameraPosition - ray.Origin;
		float camViewDotRay = -dot(CameraW, cameraRay.Direction);
		if(camViewDotRay > 0.0) // Camera faces point?
		{
			// Compute screen coord for this ray.
			vec3 proj = vec3(-dot(CameraU, cameraRay.Direction), -dot(CameraV, cameraRay.Direction), camViewDotRay);
			vec2 screenCoord = proj.xy / proj.z;
			screenCoord.x /= dot(CameraU,CameraU);
			screenCoord.y /= dot(CameraV,CameraV);

			// Valid screencoors
			if(screenCoord.x >= -1.0 && screenCoord.x < 1.0 && screenCoord.y > -1.0 && screenCoord.y <= 1.0)
			{
				float cameraDistSq = dot(cameraRay.Direction, cameraRay.Direction);
				float cameraDist = sqrt(cameraDistSq);
				cameraRay.Direction /= cameraDist;
				cameraRay.Origin = cameraRay.Direction * RAY_HIT_EPSILON + ray.Origin;

				// Hits *pinhole* camera
				if(!TraceRayAnyHit(cameraRay, cameraDist))
				{
					// Compute pdf conversion factor from image plane area to surface area.
					// The problem: A pixel sees more than only a point! -> photometric distance law (E = I cosTheta / d²) not directly applicable!
					// -> We need the solid angle and the projected area of the pixel in this point!
					// Formulas explained in (6.2) http://www.maw.dk/3d_graphics_projects/downloads/Bidirectional%20Path%20Tracing%202009.pdf
					// Also a look into SmallVCM is a good idea!
					
					// The distance to the image plane  is length(CameraW) == 1.
					// imagePointToCameraDist = length(pixelPos) = length(CameraU * screenCoord.x + CameraV * screenCoord.y + CameraW) =
					//					      = 1.0 / dot(-cameraRay.Direction, CameraW)
					// fluxToIntensity = 1/solidAngle = imagePointToCameraDist / (dot(-cameraRay.Direction, CameraW) * PixelArea) =
					//				   =  1.0 / (dot(-cameraRay.Direction, CameraW)² * PixelArea)  ------ THIS IS APPROXIMATE!
					// fluxToIrradiance =(photometric distance law)= fluxToIntensity * dot(cameraRay.Direction, Normal) / cameraDistSq

					float cosAtCamera = saturate(camViewDotRay / cameraDist); // = dot(-cameraRay.Direction, CameraW);
					cosAtCamera *= cosAtCamera;
					float fluxToIrradiance = AdjointBSDFShadingNormalCorrectedOutDotN(ray.Direction, cameraRay.Direction, geometryNormal, shadingNormal) /
											(cosAtCamera * cosAtCamera * PixelArea * cameraDistSq);

				#ifdef SAMPLEBSDF_OUTPUT_PDF
					float pdf;
					vec3 bsdf = AdjointBSDF(ray.Direction, cameraRay.Direction, materialData, shadingNormal, pdf);
				#else
					vec3 bsdf = AdjointBSDF(ray.Direction, cameraRay.Direction, materialData, shadingNormal);
				#endif

				#ifdef SAVE_LIGHT_CACHE
					float connectionLightPathToEyePath = MISHeuristic(1.0); // Next event estimate!

					float connectedPathPropability = pathProbability + DIVISOR_EPSILON;
					float mis = connectedPathPropability / (connectionLightPathToEyePath * anyPathProbabilitySum + connectedPathPropability);
					mis /= AverageLightPathLength + 1; // Equals number of techniques per BPT iteration. (Not exactly a part of the mis!)

					vec3 color = pathThroughput * (fluxToIrradiance * mis) * bsdf;
				#else
					vec3 color = pathThroughput * fluxToIrradiance * bsdf;
				#endif

					// Add Sample.
					ivec2 pixelCoord = ivec2((screenCoord*0.5 + vec2(0.5)) * BackbufferSize);
					
					WriteAtomic(color, pixelCoord);
				}
			}
		}
	#endif

	#ifdef SHOW_SPECIFIC_PATHLENGTH
		}
	#endif

		// Continue ray.
		vec3 throughput = vec3(1.0);
	#ifdef SAMPLEBSDF_OUTPUT_PDF
		float samplePDF;
		vec3 newDirection = SampleAdjointBSDF(ray.Direction, materialData, randomSeed, shadingNormal, throughput, samplePDF);
	#else
		vec3 newDirection = SampleAdjointBSDF(ray.Direction, materialData, randomSeed, shadingNormal, throughput);
	#endif
		throughput *= AdjointBSDFShadingNormalCorrection(ray.Direction, newDirection, geometryNormal, shadingNormal);
		pathThroughput *= throughput;

	#ifdef RUSSIAN_ROULETTE
		float continuationPropability = saturate(GetLuminance(throughput));
		if(Random(randomSeed) >= continuationPropability) // if terminationPropability is zero, path should be stoped -> >=
			break;
		pathThroughput /= continuationPropability; // Only change in spectrum, no energy loss. Photon (!) stays the same.
		
		#ifdef SAVE_LIGHT_CACHE
		samplePDF *= continuationPropability;
		#endif
	#endif

		ray.Direction = newDirection;
		ray.Origin += ray.Direction * RAY_HIT_EPSILON;

		// Update MIS quantitites.
	#if defined(SAVE_LIGHT_CACHE) && !defined(SAVE_LIGHT_CACHE_WARMUP)
		samplePDF = MISHeuristic(samplePDF);
		anyPathProbabilitySum = anyPathProbabilitySum * samplePDF + pathProbability;
		pathProbability *= samplePDF;
	#endif
	}
}