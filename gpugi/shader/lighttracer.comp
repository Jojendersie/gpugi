#version 440

#ifdef SAVE_LIGHT_CACHE
	#define SAMPLEBSDF_OUTPUT_PDF
#endif

#define TRINORMAL_OUTPUT
#include "stdheader.glsl"

#ifdef SAVE_LIGHT_CACHE
	#include "lightcache.glsl"
#else
	layout(binding = 4, std140) uniform LightPathTrace
	{
		int NumRaysPerLightSample;
	};
#endif


// The problem: There is no atomic vec4 operation, even with GL_NV_shader_atomic_float
// The solution: (Spin)Locks for every output pixel. (http://stackoverflow.com/questions/10652862/glsl-semaphores)
// A possible alternative solution: Gather all events in an "append buffer" and apply them via classic vertex scattering (point rendering) and blending

// coherent is necessary!
layout(binding = 0, rgba32f) coherent uniform image2D OutputTexture;
layout(binding = 1, r32ui) coherent uniform uimage2D LockTexture;


#ifdef SAVE_LIGHT_CACHE
	#define MAX_PATHLENGTH 8
#else
	#define MAX_PATHLENGTH 16
#endif

// The (often underestimated) problem:
// The number of light rays hitting a triangle does NOT depend on the shading normal!
// The fix (see also Veach Chapter 5.3 or http://ompf2.com/viewtopic.php?f=3&t=1944):
float AdjointBSDFShadingNormalCorrectedOutDotN(vec3 incomingLight, vec3 toCamera, vec3 geometryNormal, vec3 shadingNormal)
{
	// alternative without if? todo
	if(dot(incomingLight, geometryNormal) * dot(incomingLight, shadingNormal) < 0 ||
		dot(toCamera, geometryNormal) * dot(toCamera, shadingNormal) < 0)
		return 0.0;

	return saturate(abs(dot(incomingLight, shadingNormal) * dot(toCamera, geometryNormal)) / (abs(dot(incomingLight, geometryNormal)) + DIVISOR_EPSILON));

	// Alternative without correction:
	// return saturate(dot(-toCamera, shadingNormal));
}
float AdjointBSDFShadingNormalCorrection(vec3 inDir, vec3 outDir, vec3 geometryNormal, vec3 shadingNormal)
{
	// alternative without if? todo
	if(dot(inDir, geometryNormal) * dot(inDir, shadingNormal) < 0 ||
		dot(outDir, geometryNormal) * dot(outDir, shadingNormal) < 0)
		return 0.0;

	return saturate(abs(dot(inDir, shadingNormal) * dot(outDir, geometryNormal)) / (abs(dot(inDir, geometryNormal) * dot(outDir, shadingNormal)) + DIVISOR_EPSILON));
}


layout (local_size_x = 64, local_size_y = 1, local_size_z = 1) in;
void main()
{
#ifdef SAVE_LIGHT_CACHE
	// Not entirely sure if this is 100% reliable!
	// Idea is to keep the counter on GPU without any CPU interaction.
	// Problems could arise if a thread uses "NumLightCacheEntries" before Thread0 wrote this number.
	// This may happen if the GPU does not schedule block 0 as first.
	if(gl_GlobalInvocationID.x == 0)
		NumLightCacheEntries = NumRaysPerLightSample * NumInitialLightSamples;
	memoryBarrierBuffer();
#endif

	uint randomSeed = InitRandomSeed(FrameSeed, gl_GlobalInvocationID.x);
	int lightSampleIndex = int(gl_GlobalInvocationID.x / NumRaysPerLightSample);
	vec4 lightSamplePos_Norm0 = texelFetch(InitialLightSampleBuffer, lightSampleIndex * 2);
	vec4 lightIntensity_Norm1 = texelFetch(InitialLightSampleBuffer, lightSampleIndex * 2 + 1);

#ifdef SAVE_LIGHT_CACHE
	// recursive MIS construction.
	float pathProbability = 1.0;
	float anyPathProbabilitySum = 0.0;

	// Correct init of "NumLightCacheEntries" required!
	// Each thread writes its own initial light sample into the LightCache
	LightCacheEntries[gl_GlobalInvocationID.x].Flux = lightIntensity_Norm1.xyz / PI_2; // equal distributed in all directions
	LightCacheEntries[gl_GlobalInvocationID.x].MaterialIndex = -1;
	LightCacheEntries[gl_GlobalInvocationID.x].Position = lightSamplePos_Norm0.xyz;
	LightCacheEntries[gl_GlobalInvocationID.x].Normal0 = lightSamplePos_Norm0.w;
	LightCacheEntries[gl_GlobalInvocationID.x].Normal1 = lightIntensity_Norm1.w;
	LightCacheEntries[gl_GlobalInvocationID.x].PathProbability = pathProbability;
	LightCacheEntries[gl_GlobalInvocationID.x].AnyPathProbabilitySum = anyPathProbabilitySum;
	//LightCacheEntries[gl_GlobalInvocationID.x].Texcoord // texcoord empty
	//LightCacheEntries[gl_GlobalInvocationID.x].IncidentDirection // direction empty
#endif


	// Keep in mind that we are tracing flux = photons!
	// TotalFlux = Integral(I0 * cos Angle) dangle = I0 * PI
	vec3 pathThroughput = lightIntensity_Norm1.xyz * (PI / NumRaysPerLightSample);
	
	Ray ray;
	ray.Origin = lightSamplePos_Norm0.xyz;
	vec3 normal = UnpackNormal(vec2(lightSamplePos_Norm0.w, lightIntensity_Norm1.w));
	vec3 U, V;
	CreateONB(normal, U, V);
	ray.Direction = SampleUnitHemisphere(Random2(randomSeed), U, V, normal);

	for(int i=0; i<MAX_PATHLENGTH; ++i)
	{
		// Trace ray.
		Triangle triangle;
		vec3 barycentricCoord;
		float rayHit = RAY_MAX;
		vec3 geometryNormal;
		TraceRay(ray, rayHit, barycentricCoord, triangle, geometryNormal);
		if(rayHit == RAY_MAX)
			break;
		//geometryNormal = normalize(geometryNormal); geometryNormal is not normalize, but it actually does not need to be! See AdjointBSDFShadingNormalX functions
		ray.Origin = ray.Origin + rayHit * ray.Direction;	// Go to surface with recursive ray (no epsilon yet!)

		// Compute hit normal and texture coordinate.
		vec3 shadingNormal; vec2 hitTexcoord;
		GetTriangleHitInfo(triangle, barycentricCoord, shadingNormal, hitTexcoord);

		// Get Material infos.
		MaterialTextureData materialTexData = SampleMaterialData(triangle.w, hitTexcoord);

		// Save light cache entry.
#ifdef SAVE_LIGHT_CACHE
		uint lightCacheEntryIndex = atomicAdd(NumLightCacheEntries, 1);
		if(lightCacheEntryIndex < LightCacheCapacity)
		{
			LightCacheEntries[lightCacheEntryIndex].Flux = pathThroughput;
			LightCacheEntries[lightCacheEntryIndex].MaterialIndex = triangle.w;
			// Use "true" position - necessary epsilon can be easily applied in pathtracer_bidir.comp
			LightCacheEntries[lightCacheEntryIndex].Position = ray.Origin; 
			vec2 packedNormal = PackNormal(shadingNormal);
			LightCacheEntries[lightCacheEntryIndex].Normal0 = packedNormal.x;
			LightCacheEntries[lightCacheEntryIndex].Normal1 = packedNormal.y;
			LightCacheEntries[lightCacheEntryIndex].Texcoord = hitTexcoord;
			LightCacheEntries[lightCacheEntryIndex].IncidentDirection = ray.Direction;
			LightCacheEntries[lightCacheEntryIndex].PathProbability = pathProbability;
			LightCacheEntries[lightCacheEntryIndex].AnyPathProbabilitySum = anyPathProbabilitySum;
		}
#endif

		// Try to connect to camera.
		Ray cameraRay;
		cameraRay.Direction = CameraPosition - ray.Origin;
		float camViewDotRay = -dot(CameraW, cameraRay.Direction);
		if(camViewDotRay > 0.0) // Camera faces point?
		{
			// Compute screen coord for this ray.
			vec3 proj = vec3(-dot(CameraU, cameraRay.Direction), -dot(CameraV, cameraRay.Direction), camViewDotRay);
			vec2 screenCoord = proj.xy / proj.z;
			screenCoord.x /= dot(CameraU,CameraU);
			screenCoord.y /= dot(CameraV,CameraV);

			// Valid screencoors
			if(screenCoord.x >= -1.0 && screenCoord.x < 1.0 && screenCoord.y > -1.0 && screenCoord.y <= 1.0)
			{
				float cameraDistSq = dot(cameraRay.Direction, cameraRay.Direction);
				float cameraDist = sqrt(cameraDistSq);
				cameraRay.Direction /= cameraDist;
				cameraRay.Origin = cameraRay.Direction * RAY_HIT_EPSILON + ray.Origin;

				// Hits *pinhole* camera
				if(!TraceRayAnyHit(cameraRay, cameraDist))
				{
					// Compute pdf conversion factor from image plane area to surface area.
					// The problem: A pixel sees more than only a point! -> photometric distance law (E = I cosTheta / dÂ²) not applicable!
					// -> We need the solid angle and the projected area of the pixel in this point!
					// Formulas explained in (6.2) http://www.maw.dk/3d_graphics_projects/downloads/Bidirectional%20Path%20Tracing%202009.pdf
					// Also a look into SmallVCM the is a good idea!
					
					// The distance to the image plane  is length(CameraW) == 1.
					// 1/cos == length(pixelPos)
					// vec3 pixelPos = CameraU * screenCoord.x + CameraV * screenCoord.y + CameraW;
					
					float cosAtCameraPow4 = saturate(camViewDotRay / cameraDist); // = dot(-cameraRay.Direction, CameraW);
					//cosAtCameraPow4 *= cosAtCameraPow4; // Not entirely clear why this is more correct in empiric comparisions
					//cosAtCameraPow4 *= cosAtCameraPow4;
					float factor = 2.0 / PI; // TODO: Unknown origin!
					float fluxToRadiance = factor / (cosAtCameraPow4 * PixelArea * cameraDistSq);
					float fluxToIrradiance = fluxToRadiance * AdjointBSDFShadingNormalCorrectedOutDotN(ray.Direction, cameraRay.Direction, geometryNormal, shadingNormal);

				#ifdef SAMPLEBSDF_OUTPUT_PDF
					float pdf;
					vec3 bsdf = AdjointBSDF(ray.Direction, cameraRay.Direction, triangle.w, materialTexData, shadingNormal, pdf);
				#else
					vec3 bsdf = AdjointBSDF(ray.Direction, cameraRay.Direction, triangle.w, materialTexData, shadingNormal);
				#endif

				#ifdef SAVE_LIGHT_CACHE
					float connectionLightPathToEyePath = MIS(pdf);

					float connectedPathPropability = pathProbability + DIVISOR_EPSILON;
					float mis = connectedPathPropability / (connectionLightPathToEyePath * anyPathProbabilitySum + connectedPathPropability);
					mis /= NUM_SAMPLING_TECHNIQUES;

					vec3 color = pathThroughput * (fluxToIrradiance * mis) * bsdf;
				#else
					vec3 color = pathThroughput * fluxToIrradiance * bsdf;
				#endif
					

					// Add Sample.
					ivec2 pixelCoord = ivec2((screenCoord*0.5 + vec2(0.5)) * BackbufferSize);

					// Lock pixel - there is a lot you can do wrong!
					// * ..due to shared command counter
					// * ..due to buggy glsl optimizations
					// -> Good overview: http://stackoverflow.com/questions/21538555/broken-glsl-spinlock-glsl-locks-compendium
					bool hasWritten = false; // Do not use break; instead. There's a bug in the GLSL optimizer!
					do {
						if(imageAtomicCompSwap(LockTexture, pixelCoord, uint(0), uint(1)) == 0)
						{
							memoryBarrierImage();

							// Add sample
							vec4 imageVal = imageLoad(OutputTexture, pixelCoord);
							imageStore(OutputTexture, pixelCoord, vec4(imageVal.xyz + color, imageVal.w));
							
							// Release Lock
							imageAtomicExchange(LockTexture, pixelCoord, 0);
							hasWritten = true;
						}
					} while(!hasWritten);
				}
			}
		}

		// Continue ray.
		vec3 sampleThroughput = vec3(1.0);
	#ifdef SAMPLEBSDF_OUTPUT_PDF
		float samplePDF;
		vec3 newDirection = SampleAdjointBSDF(ray.Direction, triangle.w, materialTexData, randomSeed, shadingNormal, sampleThroughput, samplePDF);
	#else
		vec3 newDirection = SampleAdjointBSDF(ray.Direction, triangle.w, materialTexData, randomSeed, shadingNormal, sampleThroughput);
	#endif
		sampleThroughput *= AdjointBSDFShadingNormalCorrection(ray.Direction, newDirection, geometryNormal, shadingNormal);

	#ifdef RUSSIAN_ROULETTE
		float continuationPropability = GetLuminance(sampleThroughput);
		if(Random(randomSeed) >= continuationPropability) // if terminationPropability is zero, path should be stoped -> >=
			break;
		pathThroughput *= sampleThroughput / continuationPropability; // Only change in spectrum, no energy loss. Photon (!) stays the same.
		
		#ifdef SAVE_LIGHT_CACHE
		samplePDF *= continuationPropability;
		#endif
	#else
		pathThroughput *= sampleThroughput;
	#endif

		ray.Direction = newDirection;
		ray.Origin += ray.Direction * RAY_HIT_EPSILON;

		// Update MIS quantitites.
	#ifdef SAVE_LIGHT_CACHE
		samplePDF = MIS(samplePDF);
		anyPathProbabilitySum = anyPathProbabilitySum * samplePDF + pathProbability;
		pathProbability *= samplePDF;
	#endif
	}
}